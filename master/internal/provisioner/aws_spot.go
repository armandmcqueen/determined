package provisioner

import (
	"encoding/base64"
	"fmt"
	"sort"
	"strings"
	"time"

	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/aws/awserr"
	"github.com/aws/aws-sdk-go/service/ec2"
	"github.com/google/uuid"
	"github.com/pkg/errors"

	"github.com/determined-ai/determined/master/pkg/actor"
)

// How Spot Works:
//
// Spot instances are created asynchronously. You create a spot request, the request is validated
// and, if there is available capacity at the given price, an instance will be created (spot request
// fulfilled). We use one-time spot requests rather than persistent requests - if an instance is shut
// down, the spot request will not try to automatically launch a new instance. We do this so state
// management is slightly simpler because AWS will not be doing any provisioning outside of our code
// that we need to account for.
//
// Once the spot request has been fulfilled, the request in the API will have a pointer to the instance
// id. If the spot request is cancelled, the instance will continue to run. The spot request will have
// the status "request-canceled-and-instance-running". If the instance is stopped or terminated, either
// manually or automatically by AWS, the spot request will enter a terminal state (either cancelled,
// closed or disabled).
//
// One major issue this code handles is that the Spot Request API is eventually consistent and there may
// be a 30 second delay between creating a spot request and having it visible in listSpotRequests. We
// maintain an internal list of the spot requests we've created to prevent overprovisioning.
//
// The other major issue is that, when creating a spot request, you must pass in a validFrom parameter.
// This is a timestamp that tells AWS not to attempt to fulfill the request before this time. This time
// must be in the future or the request will be rejected as having bad params. However, the timestamp
// must be generated by our code locally and is then evaluated by the AWS API. Their clocks may not match
// our clocks so a time that we think is 10 seconds in the future could be in the past or potentially
// hours in the future. We try to account for any potential differences in clocks when generating the
// validFrom timestamp. More detail can be found in the spotRequest struct documentation below.
//
// In some cases spot requests will not be able to be fulfilled. Some errors may be permanently fatal
// (e.g. AWS does not have the instance type in this AZ) and requires user interaction to fix. In other
// cases, the error is transient (e.g. AWS account limits hit, internal system error) and may disappear
// without user interaction, but the user should be made aware of them because they may be able to intervene
// and solve the problem. It is not clear how to differentiate these cases, so we handle them identically.
//
// AWS documentation on the spot instance lifecycle -
// https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-request-status.html#spot-instance-bid-status-understand

const spotRequestIdPrefix = "sir-"
const launchTimeOffsetGrowth = time.Second * 10

type spotRequest struct {
	SpotRequestId string
	State         string
	StatusCode    *string
	StatusMessage *string
	InstanceId    *string
	CreationTime  *time.Time
}

// We need to track state to cover up flaws in the spot API
type spotState struct {
	// Keep track of spot requests that haven't entered a terminal state. This map primarily
	// exists to handle the eventual consistency problem and ensure that we don't
	// overprovision just because the requests aren't yet visible in the API.
	trackedSpotRequests map[string]*spotRequest

	// When creating a spot request, the validFrom time needs be in the future when evaluated by
	// the AWS API (otherwise the request will be rejected by AWS with a 'bad-param' error).
	// We can't rely on our clocks being in sync with AWS's. We try to approximate the clock
	// skew by creating an spot request when the provisioner is instantiated and comparing
	// time.Now() when we create the request to the timestamp that AWS records for request
	// creation. We use this value to adjust time.Now() in our code to match AWS. If that
	// approximation fails (e.g. we can't create the spot request), we assume that
	// approximateClockSkew = 0. This is a safe assumption because we also have launchTimeOffset
	// to handle the clock skew problem. However, only using launchTimeOffset may lead to
	// a longer than desired wait before a spot instance request gets fulfilled if the clock
	// skew is high or if the local clock is ahead of AWS
	approximateClockSkew *time.Duration

	// When creating a spot requests, we set the validFrom field to be time.Now() +
	// approximateClockSkew + launchTimeOffset. If clocks were perfectly synced and API calls
	// had no latency, we would want launchTimeOffset to be < 1 second so that the request
	// would start being fulfilled immediately after the spot request is submitted. However
	// API calls do have latency and there will be clock skew (and the best we can do is
	// approximate that skew). By default we set the validFrom field to be 10 seconds in the
	// future. If AWS rejects this time due to it not being in the future, we increase the
	// launchTimeOffset. If we do this enough times, we will start generating validFrom times
	// that are in the future according to AWS. One clock skew problem that is not fixed by
	// this is: if the local clock is ahead of the AWS clocks, our validFrom time may be quite
	// far in the future and AWS won't try to fulfill it until that time is reached. This is
	// why the approximateClockSkew measurement is needed.
	launchTimeOffset time.Duration
}

// listSpot lists all unfulfilled and fulfilled spot requests. If the spot request has been
// fulfilled an actual EC2 instance will be returned as an Instance. If the request has not
// been fulfilled, a fake Instance will be returned where the InstanceId is the SpotRequestId
// and the state is SpotRequestPendingAWS
func (c *awsCluster) listSpot(ctx *actor.Context) ([]*Instance, error) {
	activeSpotRequests, err := c.listActiveSpotInstanceRequests(ctx, false)
	if err != nil {
		return nil, errors.Wrap(err, "cannot describe EC2 spot requests")
	}

	// If there are any active requests that we aren't tracking, start tracking them (to
	// handle master restart)
	apiResponseMap := make(map[string]bool)
	for _, activeRequest := range activeSpotRequests {
		apiResponseMap[*activeRequest.SpotInstanceRequestId] = true
		if _, ok := c.spotState.trackedSpotRequests[*activeRequest.SpotInstanceRequestId]; !ok {
			c.spotState.trackedSpotRequests[*activeRequest.SpotInstanceRequestId] = &spotRequest{
				SpotRequestId: *activeRequest.SpotInstanceRequestId,
				State:         *activeRequest.State,
				StatusCode:    activeRequest.Status.Code,
				StatusMessage: activeRequest.Status.Message,
				InstanceId:    activeRequest.InstanceId,
				CreationTime:  activeRequest.CreateTime,
			}

		}
	}

	// If there are requests that we are tracking, but didn't get returned in listActiveSpotInstanceRequests,
	// query the API for them specifically. They could be fresh requests that aren't visible in the API yet
	// or they could have entered an inactive state for some reason. Also, keep track of the requests that
	// aren't yet visible in the AWS API for debug logs.
	missingSpotRequestIds := make([]*string, 0, 0)
	trackedRequestsNotInAWSApi := make(map[string]bool)
	for trackedSpotRequestId := range c.spotState.trackedSpotRequests {
		if _, ok := apiResponseMap[trackedSpotRequestId]; !ok {
			missingSpotRequestIds = append(missingSpotRequestIds, &trackedSpotRequestId)
			trackedRequestsNotInAWSApi[trackedSpotRequestId] = true
		}
	}

	missingSpotRequests, err := c.listSpotRequestsById(ctx, missingSpotRequestIds, false)
	if err != nil {
		return nil, errors.Wrap(err, "cannot describe EC2 spot requests")
	}

	// If any of the tracked requests failed and requires users intervention, notify the user via error
	// logs. Also stop tracking any request that is in a terminal state.
	spotRequestsToNotifyUserAbout := make([]*ec2.SpotInstanceRequest, 0, 0)
	numRequestsNoLongerTracked := 0
	for _, missingSpotRequest := range missingSpotRequests {
		delete(trackedRequestsNotInAWSApi, *missingSpotRequest.SpotInstanceRequestId)
		if *missingSpotRequest.State != "active" && *missingSpotRequest.State != "open" {
			delete(c.spotState.trackedSpotRequests, *missingSpotRequest.SpotInstanceRequestId)
			numRequestsNoLongerTracked += 1
		}
		switch *missingSpotRequest.Status.Code {
		case
			"bad-parameters",
			"constraint-not-fulfillable",
			"limit-exceeded":
			spotRequestsToNotifyUserAbout = append(spotRequestsToNotifyUserAbout, missingSpotRequest)
		}
	}

	// Log errors in chronological order
	sort.SliceStable(spotRequestsToNotifyUserAbout, func(i, j int) bool {
		return spotRequestsToNotifyUserAbout[i].CreateTime.Before(*spotRequestsToNotifyUserAbout[j].CreateTime)
	})
	for _, request := range spotRequestsToNotifyUserAbout {
		ctx.Log().
			WithField("spot-request-status-code", request.Status.Code).
			WithField("spot-request-status-message", request.Status.Message).
			WithField("spot-request-creation-time", request.CreateTime).
			Error("a spot request cannot be fulfilled and may require user intervention")
	}

	ctx.Log().
		WithField("log-type", "listSpot.updatedTrackedSpotMap").
		WithField("num-requests-being-tracked", len(c.spotState.trackedSpotRequests)).
		WithField("num-visible-as-active-in-api", len(activeSpotRequests)).
		WithField("num-no-longer-tracking-due-to-terminal-state", numRequestsNoLongerTracked).
		WithField("num-tracked-but-not-visible-in-aws-api", len(trackedRequestsNotInAWSApi)).
		Debugf("updated the list of active spot requests being tracking. "+
			"there are %d spot requests being tracked. the following requests "+
			"are being tracked but aren't visible in AWS yet: %s",
			len(c.spotState.trackedSpotRequests),
			trackedRequestsNotInAWSApi)

	// Cleanup CanceledButInstanceRunningRequests to make sure race conditions + eventual
	// consistency don't lead to us spawning EC2 instance but not cleaning them up
	canceledButInstanceRunningRequests, err := c.listCanceledButInstanceRunningSpotInstanceRequests(ctx, false)
	if err != nil {
		return nil, errors.Wrap(err, "cannot describe EC2 spot requests")
	}
	instancesToTerminate := make([]*string, 0, 0)
	for _, canceledButInstanceRunningRequest := range canceledButInstanceRunningRequests {
		instancesToTerminate = append(instancesToTerminate, canceledButInstanceRunningRequest.InstanceId)
	}
	_, err = c.terminateInstances(instancesToTerminate, false)
	if err != nil {
		ctx.Log().WithError(err).Debugf("cannot terminate EC2 instances associated with canceled spot requests")
	}

	instances, err := c.buildInstanceListFromTrackedRequestMap(ctx)
	if err != nil {
		return nil, err
	}
	return instances, nil
}

func (c *awsCluster) terminateSpot(ctx *actor.Context, instanceIDs []*string) {
	if len(instanceIDs) == 0 {
		return
	}

	instancesToTerminate := make([]*string, 0, 0)
	pendingSpotRequestsToTerminate := make([]*string, 0, 0)

	for _, instanceId := range instanceIDs {
		if strings.HasPrefix(*instanceId, spotRequestIdPrefix) {
			spotRequestId := instanceId
			pendingSpotRequestsToTerminate = append(pendingSpotRequestsToTerminate, spotRequestId)
		} else {
			instancesToTerminate = append(instancesToTerminate, instanceId)
		}
	}

	ctx.Log().
		Debugf(
			"terminating %d EC2 instances and %d spot requests: %s,  %s",
			len(instancesToTerminate),
			len(pendingSpotRequestsToTerminate),
			instancesToTerminate,
			pendingSpotRequestsToTerminate,
		)

	terminateInstancesResponse, err := c.terminateInstances(instancesToTerminate, false)
	if err != nil {
		ctx.Log().WithError(err).Error("cannot terminate EC2 instances")
	} else {
		terminated := c.newInstancesFromTerminateInstancesOutput(terminateInstancesResponse)
		ctx.Log().
			Debugf(
				"terminated %d EC2 instances: %s",
				len(terminated),
				fmtInstances(terminated),
			)
	}

	_, err = c.terminateSpotInstanceRequests(ctx, pendingSpotRequestsToTerminate, false)
	if err != nil {
		ctx.Log().WithError(err).Error("cannot terminate spot requests")
	} else {
		ctx.Log().
			Debugf(
				"terminated %d spot requests: %s",
				len(pendingSpotRequestsToTerminate),
				pendingSpotRequestsToTerminate,
			)
	}

	// TODO: Race condition - an instance could have been created between listing
	//       and terminating spot request. We could clean up the spot instances here.
	//       But it will be cleaned up on the next call to list() anyway.
}

func (c *awsCluster) launchSpot(
	ctx *actor.Context,
	instanceType instanceType,
	instanceNum int,
) {

	instType, ok := instanceType.(ec2InstanceType)
	if !ok {
		panic("cannot pass non-ec2InstanceType to ec2Cluster")
	}

	if instanceNum < 0 {
		return
	}

	ctx.Log().Infof("launching %d EC2 spot requests", instanceNum)
	resp, err := c.createSpotInstanceRequestCorrectingForClockSkew(ctx, instanceNum, false, instType)
	if err != nil {
		ctx.Log().WithError(err).Error("cannot launch EC2 spot requests")
		return
	}

	// Update the internal spotRequest tracker because there can be a large delay
	// before the API starts including these requests in listSpotRequest API calls,
	// and if we don't track it internally, we will end up overprovisioning.
	for _, request := range resp.SpotInstanceRequests {
		c.spotState.trackedSpotRequests[*request.SpotInstanceRequestId] = &spotRequest{
			SpotRequestId: *request.SpotInstanceRequestId,
			State:         *request.State,
			StatusCode:    request.Status.Code,
			StatusMessage: request.Status.Message,
			CreationTime:  request.CreateTime,
			InstanceId:    nil,
		}

		ctx.Log().Infof(
			"Launching spot request, %s, %s",
			*request.SpotInstanceRequestId,
			*request.State,
		)
	}
	return

}

// Create a spot request to try to approximate how different the local clock is from the AWS API clock.
// Record the local time.Now(), create a spot requests, then inspect the timestamp that AWS returns as
// the createTime. This will approximately tell us how different the AWS clock is from the local clock.
// It will also include the time it takes from creating the request to AWS receiving the request, but
// that is fine. Finally, the function will delete that spot request so it isn't fulfilled.
func (c *awsCluster) attemptToApproximateClockSkew(ctx *actor.Context) {

	ctx.Log().Debug("new AWS spot provisioner. launching spot request to determined approximate " +
		"clock skew between local machine and AWS API.")
	localCreateTime := time.Now()
	resp, err := c.createSpotInstanceRequest(ctx, 1, false,
		c.AWSClusterConfig.InstanceType, time.Hour*100)
	if err != nil {
		ctx.Log().
			WithError(err).
			Infof("error while launching spot request during clock skew approximation. Non-fatal error, " +
				"defaulting to assumption that AWS clock and local clock have minimal clock skew")
		zeroDur := time.Second * 0
		c.spotState.approximateClockSkew = &zeroDur
		return
	}
	awsCreateTime := resp.SpotInstanceRequests[0].CreateTime
	approxClockSkew := awsCreateTime.Sub(localCreateTime)
	ctx.Log().Infof("AWS API clock is approximately %s ahead of local machine clock",
		approxClockSkew.String())
	for {
		ctx.Log().Debugf("attempting to clean up spot request used to approximate clock skew")
		_, err = c.terminateSpotInstanceRequests(ctx,
			[]*string{resp.SpotInstanceRequests[0].SpotInstanceRequestId},
			false)
		if err == nil {
			ctx.Log().Debugf("Successfully cleaned up spot request used to approximate clock skew")
			break
		}
		if awsErr, ok := err.(awserr.Error); ok {
			ctx.Log().
				Debugf("AWS error while terminating spot request used for clock skew approximation, %s, %s",
					awsErr.Code(),
					awsErr.Message())
			if awsErr.Code() != "InvalidSpotInstanceRequestID.NotFound" {
				return
			}
		} else {
			ctx.Log().Errorf("unknown error while launch spot instances, %s", err.Error())
			return
		}
		time.Sleep(time.Second * 2)
	}
	clockSkewRoundedUp := roundDurationUp(approxClockSkew)
	c.spotState.approximateClockSkew = &clockSkewRoundedUp
}

// Convert c.spotState.trackedSpotRequests (a map) into a list of Instances. We use a
// map internally because it makes the code simpler, but the scaleDecider expects a list.
func (c *awsCluster) buildInstanceListFromTrackedRequestMap(ctx *actor.Context) ([]*Instance, error) {

	runningSpotInstanceIds := make([]*string, 0, 0)
	pendingSpotRequestsAsInstances := make([]*Instance, 0, 0)
	for _, activeRequest := range c.spotState.trackedSpotRequests {
		if activeRequest.InstanceId != nil {
			runningSpotInstanceIds = append(runningSpotInstanceIds, activeRequest.InstanceId)
		} else {
			pendingSpotRequestsAsInstances = append(pendingSpotRequestsAsInstances, &Instance{
				ID:         activeRequest.SpotRequestId,
				LaunchTime: *activeRequest.CreationTime,
				AgentName:  activeRequest.SpotRequestId,
				State:      SpotRequestPendingAWS,
			})
		}
	}

	instancesToReturn, err := c.describeInstancesById(runningSpotInstanceIds, false)
	if err != nil {
		return []*Instance{}, errors.Wrap(err, "cannot describe EC2 instances")
	}

	// Ignore any instances in the terminated state. The can happen due to eventual consistency (the
	// instance has been terminated, the spot request should be 'closed' with the status
	// 'instance-terminated-by-user', but the spot API still shows the request as 'fulfilled'). If we
	// don't correct for this, the user could have no GPUs actually provisioned, but the output of
	// listSpot is telling the scale decider that there are GPUs available so it won't provision more.
	// TODO: We could also filter out terminating instances here so slow shutdown doesn't prevent
	//       new instances from being launched.
	nonTerminalInstances := make([]*ec2.Instance, 0, 0)
	for _, inst := range instancesToReturn {
		if *inst.State.Name != "terminated" {
			nonTerminalInstances = append(nonTerminalInstances, inst)
		}
	}
	realInstances := c.newInstances(nonTerminalInstances)
	for _, inst := range realInstances {
		if inst.State == Unknown {
			ctx.Log().Errorf("unknown instance state for instance %v", inst.ID)
		}
	}

	combined := append(realInstances, pendingSpotRequestsAsInstances...)
	ctx.Log().
		WithField("log-type", "listSpot.returnCombinedList").
		Debugf("Returning list of instances: %d EC2 instances and %d dummy spot instances for %d total.",
			len(realInstances), len(pendingSpotRequestsAsInstances), len(combined))
	return combined, nil
}

func roundDurationUp(d time.Duration) time.Duration {
	roundInterval := time.Second * 10
	rounded := d.Round(roundInterval)
	if rounded < d {
		rounded = rounded + roundInterval
	}
	return rounded
}

// The AWS API requires a validFrom time that is in the future according to AWS's clock.
// See documentation of the spotState struct for more detail. This function attempts
// to create a spot request using the current values for c.spotState.approximateClockSkew
// and c.spotState.launchTimeOffset. If that fails because AWS says the validFrom time is
// not in the future, we increase c.spotState.launchTimeOffset by launchTimeOffsetGrowth.
// This can happen a maximum of 5 times before exiting with an error, to ensure that this
// function doesn't block for too long.
func (c *awsCluster) createSpotInstanceRequestCorrectingForClockSkew(
	ctx *actor.Context,
	numInstances int,
	dryRun bool,
	instanceType ec2InstanceType,
) (resp *ec2.RequestSpotInstancesOutput, err error) {
	maxRetries := 5
	for numRetries := 0; numRetries <= maxRetries; numRetries += 1 {
		offset := *c.spotState.approximateClockSkew + c.spotState.launchTimeOffset
		resp, err := c.createSpotInstanceRequest(ctx, numInstances, dryRun, instanceType, offset)
		if err == nil {
			return resp, nil
		}

		if awsErr, ok := err.(awserr.Error); ok {
			ctx.Log().Infof("AWS error while launch spot instances, %s, %s", awsErr.Code(), awsErr.Message())
			if awsErr.Code() == "InvalidTime" {
				c.spotState.launchTimeOffset = c.spotState.launchTimeOffset + launchTimeOffsetGrowth
				ctx.Log().Infof("AWS error while launch spot instances - InvalidTime. Increasing launchOffset to %s to correct for clock skew", c.spotState.launchTimeOffset.String())
			}
		} else {
			ctx.Log().Errorf("unknown error while launch spot instances, %s", err.Error())
			return nil, err
		}
	}
	return nil, err
}

func (c *awsCluster) createSpotInstanceRequest(
	ctx *actor.Context,
	numInstances int,
	dryRun bool,
	instanceType ec2InstanceType,
	launchTimeOffset time.Duration,
) (*ec2.RequestSpotInstancesOutput, error) {

	if dryRun {
		ctx.Log().Debug("dry run of createSpotInstanceRequest.")
	}
	idempotencyToken := uuid.New().String()

	validFrom := time.Now().Local().Add(*c.spotState.approximateClockSkew).Add(launchTimeOffset)
	spotInput := &ec2.RequestSpotInstancesInput{
		ClientToken:                  aws.String(idempotencyToken),
		DryRun:                       aws.Bool(dryRun),
		InstanceCount:                aws.Int64(int64(numInstances)),
		InstanceInterruptionBehavior: aws.String("terminate"),
		LaunchSpecification: &ec2.RequestSpotLaunchSpecification{
			BlockDeviceMappings: []*ec2.BlockDeviceMapping{
				{
					DeviceName: aws.String("/dev/sda1"),
					Ebs: &ec2.EbsBlockDevice{
						DeleteOnTermination: aws.Bool(true),
						VolumeSize:          aws.Int64(int64(c.RootVolumeSize)),
						VolumeType:          aws.String("gp2"),
					},
				},
			},
			ImageId:      aws.String(c.ImageID),
			InstanceType: aws.String(instanceType.name()),
			KeyName:      aws.String(c.SSHKeyName),

			UserData: aws.String(base64.StdEncoding.EncodeToString(c.ec2UserData)),
		},
		TagSpecifications: []*ec2.TagSpecification{
			{
				ResourceType: aws.String("spot-instances-request"),
				Tags: []*ec2.Tag{
					{
						Key:   aws.String(c.TagKey),
						Value: aws.String(c.TagValue),
					},
				},
			},
		},
		ValidFrom: aws.Time(validFrom),
	}

	// Excluding the SpotPrice param automatically uses the on-demand price
	if c.SpotMaxPrice != SpotPriceNotSetPlaceholder {
		spotInput.SpotPrice = aws.String(c.AWSClusterConfig.SpotMaxPrice)
	}

	spotInput.LaunchSpecification.NetworkInterfaces = []*ec2.InstanceNetworkInterfaceSpecification{
		{
			AssociatePublicIpAddress: aws.Bool(c.NetworkInterface.PublicIP),
			DeleteOnTermination:      aws.Bool(true),
			Description:              aws.String("network interface created by Determined"),
			DeviceIndex:              aws.Int64(0),
		},
	}
	if c.NetworkInterface.SubnetID != "" {
		spotInput.LaunchSpecification.NetworkInterfaces[0].SubnetId = aws.String(c.NetworkInterface.SubnetID)
	}
	if c.NetworkInterface.SecurityGroupID != "" {
		spotInput.LaunchSpecification.NetworkInterfaces[0].Groups = []*string{
			aws.String(c.NetworkInterface.SecurityGroupID),
		}
	}

	if c.IamInstanceProfileArn != "" {
		spotInput.LaunchSpecification.IamInstanceProfile = &ec2.IamInstanceProfileSpecification{
			Arn: aws.String(c.IamInstanceProfileArn),
		}
	}

	return c.client.RequestSpotInstances(spotInput)
}

func (c *awsCluster) listCanceledButInstanceRunningSpotInstanceRequests(
	ctx *actor.Context,
	dryRun bool,
) (requests []*ec2.SpotInstanceRequest, err error) {

	if dryRun {
		ctx.Log().Debug("dry run of listCanceledButInstanceRunningSpotInstanceRequests.")
	}

	input := &ec2.DescribeSpotInstanceRequestsInput{
		DryRun: aws.Bool(dryRun),
		Filters: []*ec2.Filter{
			{
				Name: aws.String(fmt.Sprintf("tag:%s", c.TagKey)),
				Values: []*string{
					aws.String(c.TagValue),
				},
			},
			{
				Name: aws.String("status-code"),
				Values: []*string{
					aws.String("request-canceled-and-instance-running"),
				},
			},
		},
	}

	response, err := c.client.DescribeSpotInstanceRequests(input)
	if err != nil {
		return
	}

	return response.SpotInstanceRequests, nil
}

func (c *awsCluster) listActiveSpotInstanceRequests(
	ctx *actor.Context,
	dryRun bool,
) (requests []*ec2.SpotInstanceRequest, err error) {

	if dryRun {
		ctx.Log().Debug("dry run of listActiveSpotInstanceRequests.")
	}

	input := &ec2.DescribeSpotInstanceRequestsInput{
		DryRun: aws.Bool(dryRun),
		Filters: []*ec2.Filter{
			{
				Name: aws.String(fmt.Sprintf("tag:%s", c.TagKey)),
				Values: []*string{
					aws.String(c.TagValue),
				},
			},
			{
				Name: aws.String("state"),
				Values: []*string{
					aws.String("open"),
					aws.String("active"),
				},
			},
		},
	}

	response, err := c.client.DescribeSpotInstanceRequests(input)
	if err != nil {
		return
	}

	return response.SpotInstanceRequests, nil
}

func (c *awsCluster) listSpotRequestsById(
	ctx *actor.Context,
	spotRequestIds []*string,
	dryRun bool,
) ([]*ec2.SpotInstanceRequest, error) {
	// List all spot requests that match a list of spot request ids. We use a filter instead
	// of the SpotInstanceRequestIds param= because the spotRequestIds in the input may not
	// yet exist in the AWS API (due to eventual consistency) and we don't want the API call
	// to fail - we want it to return successfully, just excluding those requests.

	if dryRun {
		ctx.Log().Debug("dry run of listSpotRequestsById.")
	}

	if len(spotRequestIds) == 0 {
		return make([]*ec2.SpotInstanceRequest, 0, 0), nil
	}

	input := &ec2.DescribeSpotInstanceRequestsInput{
		DryRun: aws.Bool(dryRun),
		Filters: []*ec2.Filter{
			{
				Name: aws.String(fmt.Sprintf("tag:%s", c.TagKey)),
				Values: []*string{
					aws.String(c.TagValue),
				},
			},
			{
				Name:   aws.String("spot-instance-request-id"),
				Values: spotRequestIds,
			},
		},
	}

	response, err := c.client.DescribeSpotInstanceRequests(input)
	if err != nil {
		return nil, err
	}

	return response.SpotInstanceRequests, nil
}

func (c *awsCluster) terminateSpotInstanceRequests(
	ctx *actor.Context,
	spotRequestIds []*string,
	dryRun bool,
) (*ec2.CancelSpotInstanceRequestsOutput, error) {
	if len(spotRequestIds) == 0 {
		return &ec2.CancelSpotInstanceRequestsOutput{}, nil
	}
	input := &ec2.CancelSpotInstanceRequestsInput{
		DryRun:                 aws.Bool(dryRun),
		SpotInstanceRequestIds: spotRequestIds,
	}

	return c.client.CancelSpotInstanceRequests(input)
}
